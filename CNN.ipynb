{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usef-kh/Autonoumous-Robotics/blob/master/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtaapejCCYxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Kaggle API Token\n",
        "from google.colab import files\n",
        "!pip install -q kaggle > /dev/null\n",
        "uploaded = files.upload()\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "# Load Data\n",
        "!kaggle competitions download -c tensorflow-speech-recognition-challenge > /dev/null\n",
        "\n",
        "# Unzip Data\n",
        "!apt-get install p7zip-full > /dev/null\n",
        "!p7zip -d train.7z\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RfPPVwZU0zK",
        "colab_type": "text"
      },
      "source": [
        "<!-- ## Useful Imports and Functions -->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngBpZSadzKxv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d21870f7-81dd-4787-dc52-dd8fbcc89c38"
      },
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "from scipy import signal\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.io import wavfile\n",
        "import time\n",
        "from IPython.display import Audio\n",
        "from os import walk\n",
        "from matplotlib import pyplot as plt\n",
        "import csv\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Mf8kGDGgZhw",
        "colab_type": "text"
      },
      "source": [
        "### Loading Data Helper funcitons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71mVBp9RedWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generateFiles():\n",
        "  train_audio_path = '/content/train/audio/'\n",
        "\n",
        "  # Load all filenames into a dictionary so we can call on them easily\n",
        "  files = {}\n",
        "  for (dirpath, dirnames, filenames) in walk(train_audio_path):\n",
        "    files[dirpath[21:]] = filenames\n",
        "\n",
        "  files.pop('')\n",
        "  files['_background_noise_'].remove('README.md')\n",
        "\n",
        "  return files"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrizhRjYljru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_wav(file_name, nsamples=16000):\n",
        "  wav = wavfile.read(file_name)[1]\n",
        "  \n",
        "  if wav.size < nsamples:\n",
        "      audio = np.pad(wav, (nsamples - wav.size, 0), mode='constant')\n",
        "  else:\n",
        "      audio = wav[0:nsamples]\n",
        "  return audio\n",
        "\n",
        "def get_noise(filename, nsamples=16000, stepSize = 1000):\n",
        "    wav = wavfile.read(filename)[1]\n",
        "\n",
        "    noise = []\n",
        "    for i in range((len(wav)-nsamples) // stepSize):\n",
        "      start = i*stepSize\n",
        "      subsample = wav[start: start + nsamples]\n",
        "      \n",
        "      if len(subsample) < nsamples:\n",
        "          subsample = np.pad(wav, (nsamples - subsample.size, 0), mode='constant')\n",
        "      noise.append(subsample)\n",
        "    \n",
        "    return noise"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_t-SCIBVDFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadData(files, withNoise = True):\n",
        "  train_audio_path = '/content/train/audio/'\n",
        "  \n",
        "  xtrain, ytrain, noiseArray = [], [], []\n",
        "  for label, filenames in files.items():\n",
        "    if label == '_background_noise_' and withNoise:\n",
        "  \n",
        "      for filename in filenames:\n",
        "          noise = get_noise(train_audio_path + label + '/' + filename)\n",
        "        \n",
        "          xtrain.extend(noise)\n",
        "          ytrain.extend(['silence']*len(noise))\n",
        "    \n",
        "    else:\n",
        "      for filename in filenames:\n",
        "        audio = get_wav(train_audio_path + label + '/' + filename)\n",
        "        xtrain.append(audio)\n",
        "        ytrain.append(label)\n",
        "    \n",
        "  return np.array(xtrain).astype(np.float32), np.array(ytrain)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrXGI4ZbgJGa",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Umg7_ttyVBmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def onehot(A, mapping=None):\n",
        "  labels = set(['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'silence', 'unknown'])\n",
        "\n",
        "  if mapping is None:\n",
        "    mapping = {}\n",
        "    maptolable = {}\n",
        "    for i, label in enumerate(labels):\n",
        "      temp = [0] * len(labels)\n",
        "      temp[i] = 1\n",
        "      mapping[label] = temp\n",
        "      maptolable[i] = label\n",
        "      \n",
        "  res = []\n",
        "  for label in A:\n",
        "    if label in labels:\n",
        "      res.append(mapping[label])\n",
        "    else:\n",
        "      res.append(mapping['unknown'])\n",
        "  \n",
        "  return np.array(res), mapping, maptolable"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqFoE7y1ge7e",
        "colab_type": "text"
      },
      "source": [
        "### Other Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvCA96V9ghCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1(y_true, y_pred):\n",
        "  \"\"\"Macro F1 Score\n",
        "\n",
        "  A custom metric function that computes the average of the f1 scores \n",
        "  across all classesin a multiclass classificaiton problem\n",
        "  \"\"\"\n",
        "  def recall(y_true, y_pred):\n",
        "    \"\"\"Recall metric.\n",
        "\n",
        "    Only computes a batch-wise average of recall.\n",
        "\n",
        "    Computes the recall, a metric for multi-label classification of\n",
        "    how many relevant items are selected.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "  def precision(y_true, y_pred):\n",
        "    \"\"\"Precision metric.\n",
        "\n",
        "    Only computes a batch-wise average of precision.\n",
        "\n",
        "    Computes the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "    \n",
        "  precision = precision(y_true, y_pred)\n",
        "  recall = recall(y_true, y_pred)\n",
        "  return 2*((precision * recall)/(precision + recall + K.epsilon()))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_W4p61jn3l6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def swish(x, beta = 1):\n",
        "    return (x * K.sigmoid(beta * x))\n",
        "\n",
        "# Getting the Custom object and updating them \n",
        "from keras.utils.generic_utils import get_custom_objects \n",
        "from keras.layers import Activation \n",
        "  \n",
        "# Below in place of swish you can take any custom key for the name  \n",
        "get_custom_objects().update({'swish': Activation(swish)}) "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWuD4_atgn4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def performance_curves(history, metrics):\n",
        "  def generate_plot(metric):\n",
        "    train = history.history[metric]\n",
        "    val = history.history['val_' + metric]\n",
        "    x_axis = range(1, len(history.history[metric])+1)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(x_axis, train, label=\"Training \" + metric)\n",
        "    plt.plot(x_axis, val, label=\"Validation \" + metric)\n",
        "\n",
        "    plt.ylabel(metric)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.title('Epochs vs ' + metric)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    if metric == 'loss':\n",
        "      print('Minimum Validation Loss is:', str(min(val)))\n",
        "      print('Epoch: ', str(val.index(min(val)) + 1))\n",
        "    else:\n",
        "      print('Maximum', metric, 'is:', str(max(val)))\n",
        "      print('Epoch: ', str(val.index(max(val)) + 1))\n",
        "  \n",
        "  for metric in ['loss'] + metrics:\n",
        "    generate_plot(metric)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIDPi5k5q_7-",
        "colab_type": "text"
      },
      "source": [
        "## Implementing CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-QM-76C4bOk",
        "colab_type": "text"
      },
      "source": [
        "### Generating Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdTWNDq255jc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "a09a0a1e-25b2-4bbd-8896-0aec397b3cf9"
      },
      "source": [
        "files = generateFiles()\n",
        "X, Y = loadData(files)\n",
        "\n",
        "debug = False\n",
        "if debug:\n",
        "  # Look at dataset size\n",
        "  print(len(X), len(Y))\n",
        "  count = 0\n",
        "  for label, samples in files.items():\n",
        "    print(label, '\\t', len(samples))\n",
        "    count += len(samples)\n",
        "\n",
        "  print(\"Number of Audio signals:\", count)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "64727 64727\n",
            "yes \t 2377\n",
            "house \t 1750\n",
            "five \t 2357\n",
            "cat \t 1733\n",
            "four \t 2372\n",
            "six \t 2369\n",
            "two \t 2373\n",
            "wow \t 1745\n",
            "nine \t 2364\n",
            "happy \t 1742\n",
            "eight \t 2352\n",
            "off \t 2357\n",
            "dog \t 1746\n",
            "_background_noise_ \t 6\n",
            "up \t 2375\n",
            "go \t 2372\n",
            "right \t 2367\n",
            "three \t 2356\n",
            "bird \t 1731\n",
            "marvin \t 1746\n",
            "on \t 2367\n",
            "tree \t 1733\n",
            "left \t 2353\n",
            "zero \t 2376\n",
            "seven \t 2377\n",
            "one \t 2370\n",
            "bed \t 1713\n",
            "sheila \t 1734\n",
            "down \t 2359\n",
            "stop \t 2380\n",
            "no \t 2375\n",
            "Number of Audio signals: 64727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n69SEfW9rjvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xfinal = X.reshape(-1, 16000, 1)\n",
        "\n",
        "Yonehot, mapping, maptolable = onehot(Y)\n",
        "Yonehot = Yonehot.reshape(-1, 1, 12)\n",
        "\n",
        "xtrain, xval, ytrain, yval = train_test_split(Xfinal, Yonehot, test_size=0.2, random_state=127)\n",
        "\n",
        "print('Number of Dimensions:', X.ndim)\n",
        "print('Dataset')\n",
        "print('\\t', Xfinal.shape, '\\t', Yonehot.shape)\n",
        "\n",
        "print('\\nTraining Data')\n",
        "print('\\t', xtrain.shape, '\\t', ytrain.shape)\n",
        "\n",
        "print('\\nValidation Data')\n",
        "print('\\t', xval.shape, '\\t', yval.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzVMLfZl4i5y",
        "colab_type": "text"
      },
      "source": [
        "### Building & Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2qWIshk2Wov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Activation, Flatten, Dropout, BatchNormalization, Conv1D, MaxPooling1D\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from keras.regularizers import l2\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(32, kernel_size=10, strides = 4, activation = 'relu', input_shape = xtrain.shape[1:]))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv1D(128, kernel_size=1, strides = 1, activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv1D(32, kernel_size=10, strides = 4, activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(3))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv1D(128, kernel_size=1, strides = 1, activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv1D(64, kernel_size=10, strides = 4, activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv1D(128, kernel_size=10, strides = 4, activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(32, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(len(mapping), activation = 'softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1, 'accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnRlaOfg95F9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(xtrain, ytrain, batch_size=128, validation_data=(xval, yval), epochs=85, shuffle=True, verbose=1)\n",
        "performance_curves(history, ['accuracy', 'f1'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD74dkha47E5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('CNN')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZroYGfR1BxA",
        "colab_type": "text"
      },
      "source": [
        "## Generating Test Data Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN0--5ubAB64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !p7zip -d test.7z > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99aUXO79yFyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mappings = {}\n",
        "# maptoLabel = {}\n",
        "# with open('mappings.csv', mode='r') as infile:\n",
        "#     reader = csv.reader(infile)\n",
        "\n",
        "#     for i, row in enumerate(reader):\n",
        "#         temp = [0]*12\n",
        "#         temp[i] = 1\n",
        "#         mappings[row[0]] = temp\n",
        "#         maptoLabel[i] = row[0]\n",
        "\n",
        "# test = []\n",
        "# with open('sample_submission.csv',mode='r') as infile:\n",
        "#     reader = csv.reader(infile)\n",
        "\n",
        "#     for row in reader:\n",
        "#         test.append(row[0])\n",
        "\n",
        "# test.pop(0)\n",
        "# print(len(test), test[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjlfFBDx0hI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = keras.models.load_model('CNN', custom_objects={'f1':f1})\n",
        "\n",
        "# test_audio_path = '/content/test/audio'\n",
        "\n",
        "# ypred = []\n",
        "# for filename in test:\n",
        "#   audio = get_wav(test_audio_path + '/' + filename)\n",
        "#   audio = audio.reshape(-1, 16000, 1)\n",
        "#   pred = model.predict(audio)\n",
        "#   ypred.append(np.argmax(pred[0][0], axis=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGe6JCge3FUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import pandas as pd\n",
        "# final = []\n",
        "\n",
        "# for pred in ypred:\n",
        "#   final.append(maptoLabel[pred])\n",
        "\n",
        "\n",
        "# df = pd.DataFrame(final)\n",
        "\n",
        "\n",
        "# df.to_csv ('final_df.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA-lwUJb0SUd",
        "colab_type": "text"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAk6ZEf0sylc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import random\n",
        "\n",
        "# noise = []\n",
        "# noisyX = []\n",
        "# noisyY = []\n",
        "# train_audio_path = '/content/train/audio/'\n",
        "  \n",
        "# for filename in files['_background_noise_']:\n",
        "#   noise_samples = get_noise(train_audio_path + '_background_noise_/' + filename)\n",
        "#   noise.extend(noise_samples)\n",
        "\n",
        "#   for x, y in zip(X, Y):\n",
        "#     for idx in np.random.randint(1,len(noise_samples),2):\n",
        "#       noise_sample = noise_samples[idx]\n",
        "\n",
        "#       noisyX.append(x + noise_sample * random.random()/10)\n",
        "#       noisyY.append(y)\n",
        "\n",
        "# print(len(X), len(Y))\n",
        "# print(len(noisyX), len(noisyY))\n",
        "\n",
        "# import IPython.display as ipd\n",
        "# ipd.Audio(noisyX[1], rate=16000)\n",
        "\n",
        "# ipd.Audio(X[0], rate=16000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}